<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>GenAI with Google Cloud + Prompt Engineering - Vitthal Mirji</title><link rel=icon type=image/png href=favicon.ico><meta name=viewport content="width=device-width,initial-scale=1"><meta itemprop=name content="GenAI with Google Cloud + Prompt Engineering"><meta itemprop=description content="From prompt to pipeline: GenAI integration with GCP + Vertex AI"><meta itemprop=datePublished content="2025-06-21T00:00:00+00:00"><meta itemprop=dateModified content="2025-06-21T00:00:00+00:00"><meta itemprop=wordCount content="830"><meta itemprop=keywords content="GenAI,Google Cloud,Vertex AI,Prompt Engineering,LLMs,AI Pipelines,AI Tools,AI Workflows,AI Applications,AI Development,AI Deployment"><meta property="og:url" content="https://vitthalmirji.com/2025/06/genai-with-google-cloud--prompt-engineering/"><meta property="og:site_name" content="Vitthal Mirji"><meta property="og:title" content="GenAI with Google Cloud + Prompt Engineering"><meta property="og:description" content="From prompt to pipeline: GenAI integration with GCP + Vertex AI"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-06-21T00:00:00+00:00"><meta property="article:modified_time" content="2025-06-21T00:00:00+00:00"><meta property="article:tag" content="GenAI"><meta property="article:tag" content="Google Cloud"><meta property="article:tag" content="Vertex AI"><meta property="article:tag" content="Prompt Engineering"><meta property="article:tag" content="LLMs"><meta property="article:tag" content="AI Pipelines"><meta name=twitter:card content="summary"><meta name=twitter:title content="GenAI with Google Cloud + Prompt Engineering"><meta name=twitter:description content="From prompt to pipeline: GenAI integration with GCP + Vertex AI"><link rel=stylesheet type=text/css media=screen href=https://vitthalmirji.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://vitthalmirji.com/css/main.css><link rel=stylesheet type=text/css href=https://vitthalmirji.com/[css/override.css]><link id=dark-scheme rel=stylesheet type=text/css href=https://vitthalmirji.com/css/dark.css><script src=https://vitthalmirji.com/js/feather.min.js></script><script src=https://vitthalmirji.com/js/main.js></script></head><body><div class="container-wide wrapper"><link rel=icon href=../../../favicon.ico sizes=any><link rel=icon type=image/png href=../../../favicon.png><link rel=apple-touch-icon href=../../../apple-touch-icon.png><link rel=manifest href=../../../site.webmanifest><meta name=theme-color content="#ffffff"><link rel=stylesheet href=../../../syntax.css><div class=header><h1 class=site-title><a href=https://vitthalmirji.com/>Vitthal Mirji</a></h1><div class=site-description><p>Software Engineering, Data Engineering, GNU/Linux, Data, ML, and other things</p><nav class="nav social"><ul class=flat><li><a href=https://github.com/vim89/ title=Github><i data-feather=github></i></a></li><li><a href=https://twitter.com/whoami_vim/ title=Twitter><i data-feather=twitter></i></a></li><li><a href=https://www.linkedin.com/in/vitthal10/ title=LinkedIn><i data-feather=linkedin></i></a></li><li><a href=../../../index.xml title=RSS><i data-feather=rss></i></a></li><span class=scheme-toggle><a href=# id=scheme-toggle></a></ul></nav></div><nav class=nav><ul class=flat><li><a href=../../../>Home</a></li><li><a href=../../../about>About</a></li><li><a href=../../../tags>Tags & Stats</a></li></ul></nav></div><div class=article-nav id=article-nav-id><div class=post><div class=post-header><div class=meta><div class=date><span class=day>21</span>
<span class=rest>Jun 2025</span></div></div><div class=matter><h1 class=title>GenAI with Google Cloud + Prompt Engineering</h1></div></div><aside class=toc id=static-toc><header><h3>Contents</h3></header><nav id=TableOfContents><ol><li><a href=#-introduction>🚀 Introduction</a></li><li><a href=#-1-what-is-prompt-engineering>🎯 1. What is Prompt Engineering?</a></li><li><a href=#-2-prompt-engineering-techniques>🧪 2. Prompt Engineering Techniques</a></li><li><a href=#-3-prompt-example-for-code-summarization>🧩 3. Prompt Example for Code Summarization</a></li><li><a href=#-4-automating-prompts-with-vertex-ai>🛠️ 4. Automating Prompts with Vertex AI</a></li><li><a href=#-5-genai-pipeline-architecture>🏗️ 5. GenAI Pipeline Architecture</a></li><li><a href=#-6-sample-code-kotlin-client--vertex-ai-interaction>⚙️ 6. Sample code: Kotlin client + Vertex AI interaction</a></li><li><a href=#-7-prompt-tuning--optimizer-usage>📐 7. Prompt Tuning + Optimizer Usage</a></li><li><a href=#-8-full-sequence-diagram>🔄 8. Full sequence diagram</a></li><li><a href=#-9-handling-model-safety-and-bias>✨ 9. Handling model safety and bias</a></li><li><a href=#-11-cost-vs-latency-patterns>📊 11. Cost vs Latency Patterns</a></li><li><a href=#-12-iterative-prompt-improvement>🤹‍♂️ 12. Iterative Prompt Improvement</a></li><li><a href=#-13-conclusion>🏁 13. Conclusion</a></li><li><a href=#-references>📚 References</a></li></ol></nav></aside><h2 id=-introduction>🚀 Introduction</h2><p>Welcome to the world of <strong>GenAI on Google Cloud</strong>, where prompts become pipelines and imagination drives innovation. In this post, we’ll explore how to design, iterate, and deploy GenAI pipelines using <strong>Vertex AI</strong>, smart <strong>prompt engineering</strong>, and scalable <strong>GCP services</strong>. Strap in—this is going to get technical, creative, and fun.</p><hr><h2 id=-1-what-is-prompt-engineering>🎯 1. What is Prompt Engineering?</h2><p>Prompt engineering is the art and science of crafting inputs to LLMs to elicit desired outputs. It’s like programming with words. 🚀</p><p>Best practices include: </p><ul><li>Give clear and specific instructions</li><li>Provide relevant system messages</li><li>Use few‑shot examples</li><li>Add contextual info</li><li>Structure your prompt</li><li>Ask the model to explain its reasoning<br><a href="https://bgiri-gcloud.medium.com/generative-ai-with-vertex-ai-prompt-design-for-enterprise-use-case-077ce7671065?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:0‡Medium</a>
<a href="https://cloud.google.com/discover/what-is-prompt-engineering?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:1‡Google Cloud</a>
<a href="https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-design-strategies?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:2‡Google Cloud</a>
<a href="https://www.cloudskillsboost.google/focuses/86501?parent=catalog&amp;utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:3‡Google Cloud Skills Boost</a></li></ul><hr><h2 id=-2-prompt-engineering-techniques>🧪 2. Prompt Engineering Techniques</h2><table><thead><tr><th>Technique</th><th>Description</th><th>Benefit</th></tr></thead><tbody><tr><td>Zero‑shot</td><td>Tell the model what to do directly</td><td>Fast but less reliable</td></tr><tr><td>Few‑shot</td><td>Provide a few input/output examples</td><td>Guides model behavior</td></tr><tr><td>Chain‑of‑Thought</td><td>Ask the model to “think step by step”</td><td>Improves multi‑step reasoning <a href="https://en.wikipedia.org/wiki/Prompt_engineering?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:4‡Wikipedia</a></td></tr><tr><td>Self‑consistency</td><td>Generate multiple answers, pick the majority</td><td>Reduces hallucinations</td></tr><tr><td>Tree‑of‑Thought</td><td>Explore multiple reasoning paths in parallel</td><td>More robust solutions</td></tr></tbody></table><hr><h2 id=-3-prompt-example-for-code-summarization>🧩 3. Prompt Example for Code Summarization</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>System: You are a helpful assistant.
</span></span><span class=line><span class=cl>User: Here&#39;s a Python function:
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>fib</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>n</span> <span class=o>&lt;=</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>n</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>fib</span><span class=p>(</span><span class=n>n</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=n>fib</span><span class=p>(</span><span class=n>n</span><span class=o>-</span><span class=mi>2</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Task: Explain the purpose and optimization approach.
Few‑shot version:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>System: You are an expert Python engineer.
</span></span><span class=line><span class=cl>Example 1:
</span></span><span class=line><span class=cl>Input:
</span></span><span class=line><span class=cl>```python
</span></span><span class=line><span class=cl>def add(a, b):
</span></span><span class=line><span class=cl>    return a + b
</span></span></code></pre></td></tr></table></div></div><p>Output: &ldquo;This function returns the sum..&rdquo;
Example 2:
Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>fact</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>1</span> <span class=k>if</span> <span class=n>n</span><span class=o>==</span><span class=mi>0</span> <span class=k>else</span> <span class=n>n</span><span class=o>*</span><span class=n>fact</span><span class=p>(</span><span class=n>n</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output: “This computes factorial recursively…”
Now:
Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>fib</span><span class=p>(</span><span class=n>n</span><span class=p>):</span> <span class=err>…</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:
&ldquo;This function computes Fibonacci numbers recursively. It can be optimized using memoization to avoid redundant calculations.&rdquo;</p><hr><h2 id=-4-automating-prompts-with-vertex-ai>🛠️ 4. Automating Prompts with Vertex AI</h2><p>Prompt automation with the Vertex AI Prompt Optimizer service:</p><ul><li>Upload labeled examples</li><li>Configure system instruction + few‑shots</li><li>Run optimizer to get best prompt template<br><a href="https://developers.googleblog.com/en/enhance-your-prompts-with-vertex-ai-prompt-optimizer/?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:5‡Google Developers Blog</a>
<a href="https://en.wikipedia.org/wiki/Prompt_engineering?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:6‡Wikipedia</a></li></ul><hr><h2 id=-5-genai-pipeline-architecture>🏗️ 5. GenAI Pipeline Architecture</h2><pre class=mermaid>
  flowchart TD
  subgraph &#34;Client&#34;
    A[User App]
  end
  A --&gt; |text,input| B[Cloud Function / API]
  B --&gt; C[Vertex AI Text Generation]
  C --&gt; D[Vertex AI Prompt Optimizer / Eval]
  D --&gt; E[Cloud Run / Storage]
  E --&gt; F[Frontend Dashboard]
</pre><p>Highlights: serverless endpoints, prompt tuning, GenAI vetting, and storage.</p><h2 id=-6-sample-code-kotlin-client--vertex-ai-interaction>⚙️ 6. Sample code: Kotlin client + Vertex AI interaction</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-kotlin data-lang=kotlin><span class=line><span class=cl><span class=k>val</span> <span class=py>model</span> <span class=p>=</span> <span class=nc>TextGenerationModel</span><span class=p>.</span><span class=n>fromPretrained</span><span class=p>(</span><span class=s2>&#34;text-bison@001&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>suspend</span> <span class=k>fun</span> <span class=nf>generateAnswer</span><span class=p>(</span><span class=n>prompt</span><span class=p>:</span> <span class=n>String</span><span class=p>):</span> <span class=n>String</span> <span class=p>=</span>
</span></span><span class=line><span class=cl>    <span class=n>coroutineScope</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=p>.</span><span class=n>predict</span><span class=p>(</span><span class=n>prompt</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>temperature</span> <span class=p>=</span> <span class=m>0.2</span>
</span></span><span class=line><span class=cl>            <span class=n>maxOutputTokens</span> <span class=p>=</span> <span class=m>512</span>
</span></span><span class=line><span class=cl>        <span class=p>}.</span><span class=n>text</span><span class=p>.</span><span class=n>trim</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>fun</span> <span class=nf>handle</span><span class=p>(</span><span class=n>req</span><span class=p>:</span> <span class=n>Request</span><span class=p>):</span> <span class=n>Response</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>val</span> <span class=py>prompt</span> <span class=p>=</span> <span class=n>req</span><span class=p>.</span><span class=n>json</span><span class=p>.</span><span class=n>getString</span><span class=p>(</span><span class=s2>&#34;question&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>val</span> <span class=py>ans</span> <span class=p>=</span> <span class=n>runBlocking</span> <span class=p>{</span> <span class=n>generateAnswer</span><span class=p>(</span><span class=n>promptWithContext</span><span class=p>(</span><span class=n>prompt</span><span class=p>))</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nc>Response</span><span class=p>.</span><span class=n>json</span><span class=p>(</span><span class=n>mapOf</span><span class=p>(</span><span class=s2>&#34;answer&#34;</span> <span class=n>to</span> <span class=n>ans</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=-7-prompt-tuning--optimizer-usage>📐 7. Prompt Tuning + Optimizer Usage</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-kotlin data-lang=kotlin><span class=line><span class=cl><span class=k>val</span> <span class=py>optimizer</span> <span class=p>=</span> <span class=n>PromptOptimizerClient</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>val</span> <span class=py>best</span> <span class=p>=</span> <span class=n>optimizer</span><span class=p>.</span><span class=n>optimize</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>instruction</span> <span class=p>=</span> <span class=s2>&#34;Answer travel queries concisely.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>examples</span> <span class=p>=</span> <span class=n>examplePairs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=p>=</span> <span class=s2>&#34;text-bison@001&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>println</span><span class=p>(</span><span class=s2>&#34;Optimized prompt:</span><span class=se>\n</span><span class=si>${best.prompt}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=-8-full-sequence-diagram>🔄 8. Full sequence diagram</h2><pre class=mermaid>
  sequenceDiagram
  participant U as User
  participant API
  participant Vertex
  participant Opt as PromptOptimizer
  participant Store
  participant Dash

  U-&gt;&gt;API: POST /ask {question}
  API-&gt;&gt;Vertex: generate with best-prompt
  Vertex-&gt;&gt;Opt: evaluate candidate prompts
  Opt--&gt;&gt;Vertex: return optimized prompt
  Vertex--&gt;&gt;API: answer
  API-&gt;&gt;Store: save Q/A
  Dash-&gt;&gt;Store: query history
</pre><h2 id=-9-handling-model-safety-and-bias>✨ 9. Handling model safety and bias</h2><p>Vertex AI supports responsible AI via:</p><ul><li>System instructions & filters</li><li>Safety policies, content moderation</li><li>Hallucination detection and fallback</li></ul><p>@@ 🧩 10. RAG + Contextual prompting</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-kotlin data-lang=kotlin><span class=line><span class=cl><span class=k>val</span> <span class=py>docs</span> <span class=p>=</span> <span class=n>retriever</span><span class=p>.</span><span class=n>search</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>val</span> <span class=py>context</span> <span class=p>=</span> <span class=n>docs</span><span class=p>.</span><span class=n>join</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n\n</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>val</span> <span class=py>prompt</span> <span class=p>=</span> <span class=s>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s>System: You are expert.
</span></span></span><span class=line><span class=cl><span class=s>Context: </span><span class=si>$context</span><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>Question: </span><span class=si>$query</span><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>Answer following guidelines...
</span></span></span><span class=line><span class=cl><span class=s>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=k>val</span> <span class=py>resp</span> <span class=p>=</span> <span class=n>model</span><span class=p>.</span><span class=n>predict</span><span class=p>(</span><span class=n>prompt</span><span class=p>).</span><span class=n>text</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=-11-cost-vs-latency-patterns>📊 11. Cost vs Latency Patterns</h2><p>The table below compares key stages in a GenAI pipeline using Vertex AI and related GCP services:</p><table><thead><tr><th><strong>Stage</strong></th><th><strong>Service</strong></th><th><strong>Typical Latency</strong></th><th><strong>Pricing Model</strong></th><th><strong>Estimated Cost</strong></th></tr></thead><tbody><tr><td>API endpoint</td><td>Cloud Run / Functions</td><td>~50 ms</td><td>vCPU/time</td><td>Low; sub‑$0.01 per request</td></tr><tr><td>Prompt optimizer</td><td>Vertex AI Prompt Optimizer</td><td>~500 ms</td><td>Batch optimization</td><td>Moderate; costs for optimizer operations</td></tr><tr><td>LLM generation</td><td>Vertex AI (Gemini/Text‑Bison)</td><td>200–1,000 ms</td><td>Token-based ($/1k chars) <a href="https://cloud.google.com/vertex-ai/generative-ai/pricing?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:0‡cloud.google.com</a>
<a href="https://www.dhiwise.com/post/vertex-ai-llm-google-ai-guide?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:1‡dhiwise.com</a>
<a href="https://console.cloud.google.com/vertex-ai/model-garden?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:2‡console.cloud.google.com</a>
<a href="https://cloudchipr.com/blog/vertex-ai?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:3‡cloudchipr.com</a></td><td>Gemini 2.5 Flash: $0.10/$0.40 per million input/output tokens <a href="https://ai.google.dev/gemini-api/docs/pricing?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">oai_citation:4‡ai.google.dev</a></td></tr><tr><td>RAG retrieval</td><td>Vertex Search or Datastore</td><td>~100 ms</td><td>Per‑query or per-index node-hour</td><td>Low; depends on query volume</td></tr></tbody></table><h2 id=-12-iterative-prompt-improvement>🤹‍♂️ 12. Iterative Prompt Improvement</h2><p>Steps:</p><ol><li>Start with zero-shot</li><li>Add few-shot examples</li><li>Optimize with Prompt Optimizer</li><li>Evaluate via GenAI Evaluation APIs</li><li>Log prompts & outcomes for telemetry</li></ol><h2 id=-13-conclusion>🏁 13. Conclusion</h2><p>We’ve covered:</p><ul><li>Techniques (zero/few‑shot, CoT, self‑consistency)</li><li>Automation via Prompt Optimizer</li><li>Serverless pipelines + GenAI</li><li>Diagrams, code, and best practices</li></ul><p>GenAI on GCP feels fresh, fun, and enterprise‑grade. Enjoy!</p><h2 id=-references>📚 References</h2><ul><li><a href="https://cloud.google.com/discover/what-is-prompt-engineering?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">Google Cloud: What is Prompt Engineering?</a></li><li><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-design-strategies?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">Google Cloud: Prompt Design Strategies</a></li><li><a href="https://www.cloudskillsboost.google/focuses/86501?parent=catalog&amp;utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">Google Cloud Skills Boost: Prompt Design for Enterprise Use Case</a></li><li><a href="https://en.wikipedia.org/wiki/Prompt_engineering?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">Wikipedia: Prompt Engineering</a></li><li><a href="https://developers.googleblog.com/en/enhance-your-prompts-with-vertex-ai-prompt-optimizer/?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">Google Developers Blog: Enhance Your Prompts with Vertex AI Prompt Optimizer</a></li><li><a href="https://bgiri-gcloud.medium.com/generative-ai-with-vertex-ai-prompt-design-for-enterprise-use-case-077ce7671065?utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">Medium: Generative AI with Vertex AI - Prompt Design for Enterprise Use Case</a></li><li><a href="https://cloud.google.com/vertex-ai/generative-ai/docs?hl=en&amp;utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">Google Cloud: Vertex AI Generative AI</a></li><li><a href="https://cloud.google.com/vertex-ai/docs/generative-ai/text-generation?hl=en&amp;utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">Google Cloud: Vertex AI Text Generation</a></li><li><a href="https://cloud.google.com/vertex-ai/docs/generative-ai/prompt-optimizer?hl=en&amp;utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">Google Cloud: Vertex AI Prompt Optimizer</a></li><li><a href="https://cloud.google.com/vertex-ai/docs/generative-ai/evaluation?hl=en&amp;utm_source=chatgpt.com" target=_blank rel="nofollow noopener noreferrer">Google Cloud: Vertex AI Evaluation</a></li></ul></div><nav class="hide-on-mobile section-nav"><nav id=TableOfContents><ol><li><a href=#-introduction>🚀 Introduction</a></li><li><a href=#-1-what-is-prompt-engineering>🎯 1. What is Prompt Engineering?</a></li><li><a href=#-2-prompt-engineering-techniques>🧪 2. Prompt Engineering Techniques</a></li><li><a href=#-3-prompt-example-for-code-summarization>🧩 3. Prompt Example for Code Summarization</a></li><li><a href=#-4-automating-prompts-with-vertex-ai>🛠️ 4. Automating Prompts with Vertex AI</a></li><li><a href=#-5-genai-pipeline-architecture>🏗️ 5. GenAI Pipeline Architecture</a></li><li><a href=#-6-sample-code-kotlin-client--vertex-ai-interaction>⚙️ 6. Sample code: Kotlin client + Vertex AI interaction</a></li><li><a href=#-7-prompt-tuning--optimizer-usage>📐 7. Prompt Tuning + Optimizer Usage</a></li><li><a href=#-8-full-sequence-diagram>🔄 8. Full sequence diagram</a></li><li><a href=#-9-handling-model-safety-and-bias>✨ 9. Handling model safety and bias</a></li><li><a href=#-11-cost-vs-latency-patterns>📊 11. Cost vs Latency Patterns</a></li><li><a href=#-12-iterative-prompt-improvement>🤹‍♂️ 12. Iterative Prompt Improvement</a></li><li><a href=#-13-conclusion>🏁 13. Conclusion</a></li><li><a href=#-references>📚 References</a></li></ol></nav></nav></div><div class=post><hr class=footer-separator><div class=tags><ul class=flat><li class=tag-li><a href=../../../tags/genai>GenAI</a></li><li class=tag-li><a href=../../../tags/google-cloud>Google Cloud</a></li><li class=tag-li><a href=../../../tags/vertex-ai>Vertex AI</a></li><li class=tag-li><a href=../../../tags/prompt-engineering>Prompt Engineering</a></li><li class=tag-li><a href=../../../tags/llms>LLMs</a></li><li class=tag-li><a href=../../../tags/ai-pipelines>AI Pipelines</a></li><li class=tag-li><a href=../../../tags/ai-tools>AI Tools</a></li><li class=tag-li><a href=../../../tags/ai-workflows>AI Workflows</a></li><li class=tag-li><a href=../../../tags/ai-applications>AI Applications</a></li><li class=tag-li><a href=../../../tags/ai-development>AI Development</a></li><li class=tag-li><a href=../../../tags/ai-deployment>AI Deployment</a></li></ul></div><div class=back><a href=https://github.com/vim89/vitthalmirji.com/blob/master/content/posts/2025/06/genai-vertex-gcp/index.md title=github><i data-feather=github></i> Edit this on GitHub</a></div><div class=back><a href=https://vitthalmirji.com/><span aria-hidden=true>← Back</span></a></div><div class=back>Next time, we'll talk about <i>"What Tiger King can teach us about x86 Assembly"</i></div></div></div><div class="footer wrapper"><nav class=nav><div>2025 © Copyright notice</div></nav></div><script>feather.replace()</script><script type=module>
	import mermaid from "https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs";

	const getMermaidTheme = () => {
		const savedScheme = localStorage.getItem('scheme');
		if (savedScheme) {
			return savedScheme === 'dark' ? 'dark' : 'default';
		}
		return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
	};

	mermaid.initialize({
		startOnLoad: true,
		theme: getMermaidTheme()
	});

	const applyTheme = () => {
		const newTheme = getMermaidTheme();
		mermaid.initialize({
			startOnLoad: true,
			theme: newTheme
		});
	};

	window.addEventListener('storage', (event) => {
		if (event.key === 'scheme') {
			applyTheme();
		}
	});

	window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', applyTheme);
</script><script>document.querySelectorAll("pre code").forEach(e=>{const t=document.createElement("button");t.innerText="📋",t.onclick=()=>{navigator.clipboard.writeText(e.innerText),t.innerText="✅",setTimeout(()=>t.innerText="📋",2e3)},e.parentElement.style.position="relative",t.style.position="absolute",t.style.top="8px",t.style.right="8px",e.parentElement.appendChild(t)})</script><script>var enableTruncate=!0,filterDepth=!1;const MAX_DEPTH=9;window.addEventListener("DOMContentLoaded",()=>{const e=new IntersectionObserver(e=>{e.reverse().forEach(e=>{const n=e.target.getAttribute("id");if(e.intersectionRatio>0){var t=document.querySelectorAll(`nav li a[href="#${n}"]`);t!=null&&t.forEach(e=>{if(e!=null){var t=getDepth(e.parentElement);filterDepth&&t<=MAX_DEPTH&&(clearActiveStatesInTableOfContents(),e.parentElement.classList.add("active"))}else filterDepth||(clearActiveStatesInTableOfContents(),e.parentElement.classList.add("active"))})}})});document.querySelectorAll("h1[id],h2[id],h3[id],h4[id]").forEach(t=>{e.observe(t)})});function isVisible(e){if(!(e instanceof Element))return!1;const n=getComputedStyle(e);if(n.display==="none")return!1;if(n.visibility!=="visible")return!1;if(n.opacity<.1)return!1;if(e.offsetWidth+e.offsetHeight+e.getBoundingClientRect().height+e.getBoundingClientRect().width===0)return!1;const t={x:e.getBoundingClientRect().left+e.offsetWidth/2,y:e.getBoundingClientRect().top+e.offsetHeight/2};if(t.x<0)return!1;if(t.x>(document.documentElement.clientWidth||window.innerWidth))return!1;if(t.y<0)return!1;if(t.y>(document.documentElement.clientHeight||window.innerHeight))return!1;let s=document.elementFromPoint(t.x,t.y);do if(s===e)return!0;while(s=s.parentNode)return!1}function clearActiveStatesInTableOfContents(){document.querySelectorAll("nav li").forEach(e=>{e.classList.remove("active")})}function getDepth(e){for(var t=0;e!==null&&e.tagName.toLowerCase()!=="ul";)t++,e=e.parentElement;return t}function navItems(){var e=document.querySelectorAll("nav nav li a");return Array.from(e).filter(e=>e.href!=null&&e.hash.startsWith("#"))}function lasItemInNavBarVisible(){var e=navItems().slice(-1)[0];return isVisible(e)}document.addEventListener("DOMContentLoaded",function(){if(!enableTruncate)return;var e=navItems();console.log(e),lasItemInNavBarVisible()||(filterDepth=!0,e.forEach(function(e){var t=getDepth(e.parentElement);t>MAX_DEPTH&&e.parentElement.classList.add("depth-nested")}))})</script></body></html>