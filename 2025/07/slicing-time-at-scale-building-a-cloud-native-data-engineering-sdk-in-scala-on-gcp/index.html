<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Slicing Time at Scale: Building a Cloud-Native Data Engineering SDK in Scala (on GCP) - Vitthal Mirji</title><link rel=icon type=image/png href=favicon.ico><meta name=viewport content="width=device-width,initial-scale=1"><meta itemprop=name content="Slicing Time at Scale: Building a Cloud-Native Data Engineering SDK in Scala (on GCP)"><meta itemprop=description content="How we rewrote the rules of partitioning, change detection, and cloud-native CDC‚Äîan opinionated, sarcastic, technically deep SDK story powered by Scala and Google Cloud."><meta itemprop=datePublished content="2025-07-18T00:00:00+00:00"><meta itemprop=dateModified content="2025-07-18T00:00:00+00:00"><meta itemprop=wordCount content="2602"><meta itemprop=keywords content="Gcp,Scala,Sdk,Data Engineering,Cdc,Partitions,Bigquery,Dataproc,Cloud"><meta property="og:url" content="https://vitthalmirji.com/2025/07/slicing-time-at-scale-building-a-cloud-native-data-engineering-sdk-in-scala-on-gcp/"><meta property="og:site_name" content="Vitthal Mirji"><meta property="og:title" content="Slicing Time at Scale: Building a Cloud-Native Data Engineering SDK in Scala (on GCP)"><meta property="og:description" content="How we rewrote the rules of partitioning, change detection, and cloud-native CDC‚Äîan opinionated, sarcastic, technically deep SDK story powered by Scala and Google Cloud."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-07-18T00:00:00+00:00"><meta property="article:modified_time" content="2025-07-18T00:00:00+00:00"><meta property="article:tag" content="Gcp"><meta property="article:tag" content="Scala"><meta property="article:tag" content="Sdk"><meta property="article:tag" content="Data Engineering"><meta property="article:tag" content="Cdc"><meta property="article:tag" content="Partitions"><meta name=twitter:card content="summary"><meta name=twitter:title content="Slicing Time at Scale: Building a Cloud-Native Data Engineering SDK in Scala (on GCP)"><meta name=twitter:description content="How we rewrote the rules of partitioning, change detection, and cloud-native CDC‚Äîan opinionated, sarcastic, technically deep SDK story powered by Scala and Google Cloud."><link rel=stylesheet type=text/css media=screen href=https://vitthalmirji.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://vitthalmirji.com/css/main.css><link rel=stylesheet type=text/css href=https://vitthalmirji.com/[css/override.css]><link id=dark-scheme rel=stylesheet type=text/css href=https://vitthalmirji.com/css/dark.css><script src=https://vitthalmirji.com/js/feather.min.js></script><script src=https://vitthalmirji.com/js/main.js></script></head><body><div class="container-wide wrapper"><link rel=icon href=../../../favicon.ico sizes=any><link rel=icon type=image/png href=../../../favicon.png><link rel=apple-touch-icon href=../../../apple-touch-icon.png><link rel=manifest href=../../../site.webmanifest><meta name=theme-color content="#ffffff"><link rel=stylesheet href=../../../syntax.css><div class=header><h1 class=site-title><a href=https://vitthalmirji.com/>Vitthal Mirji</a></h1><div class=site-description><p>Software Engineering, Data Engineering, GNU/Linux, Data, ML, and other things</p><nav class="nav social"><ul class=flat><li><a href=https://github.com/vim89/ title=Github><i data-feather=github></i></a></li><li><a href=https://twitter.com/whoami_vim/ title=Twitter><i data-feather=twitter></i></a></li><li><a href=https://www.linkedin.com/in/vitthal10/ title=LinkedIn><i data-feather=linkedin></i></a></li><li><a href=../../../index.xml title=RSS><i data-feather=rss></i></a></li><span class=scheme-toggle><a href=# id=scheme-toggle></a></ul></nav></div><nav class=nav><ul class=flat><li><a href=../../../>Home</a></li><li><a href=../../../about>About</a></li><li><a href=../../../tags>Tags & Stats</a></li></ul></nav></div><div class=article-nav id=article-nav-id><div class=post><div class=post-header><div class=meta><div class=date><span class=day>18</span>
<span class=rest>Jul 2025</span></div></div><div class=matter><h1 class=title>Slicing Time at Scale: Building a Cloud-Native Data Engineering SDK in Scala (on GCP)</h1></div></div><aside class=toc id=static-toc><header><h3>Contents</h3></header><nav id=TableOfContents><ol><li><a href=#the-madness-of-scale-why-just-read-everything-is-dead>The Madness of Scale: Why ‚ÄúJust Read Everything‚Äù Is Dead</a><ol><li><a href=#the-real-world-pain-symptoms-of-scale-gone-wrong>The Real-World Pain: Symptoms of Scale Gone Wrong</a></li><li><a href=#common-anti-patterns-in-na√Øve-cdc-logic>Common Anti-patterns in Na√Øve CDC Logic</a></li><li><a href=#what-we-needed-discipline-encoded-as-code>What We Needed: Discipline Encoded as Code</a></li></ol></li><li><a href=#sdk-philosophy-beyond-utilities-into-a-modular-toolkit>SDK Philosophy: Beyond Utilities, Into a Modular Toolkit</a><ol><li><a href=#architectural-decisions-why-modularity>Architectural Decisions: Why Modularity?</a></li><li><a href=#trait-based-abstractions-and-avoiding-implicits>Trait-Based Abstractions and Avoiding Implicits</a></li><li><a href=#sdk-lifecycle-publishing-and-versioning>SDK Lifecycle: Publishing and Versioning</a></li><li><a href=#testability-and-continuous-integration>Testability and Continuous Integration</a></li></ol></li><li><a href=#partition-whispering-getaffectedpartitions>Partition Whispering: <code>getAffectedPartitions</code></a><ol><li><a href=#metadata-snapshotting-capturing-the-state-of-the-lake>Metadata Snapshotting: Capturing the State of the Lake</a></li><li><a href=#cloud-specific-quirks-gcs-eventual-consistency-and-more>Cloud-Specific Quirks: GCS Eventual Consistency and More</a></li><li><a href=#partition-extraction-strategies>Partition Extraction Strategies</a></li></ol></li><li><a href=#cdc-without-acid-performdelta>CDC Without ACID: <code>performDelta</code></a><ol><li><a href=#deep-dive-join-strategy-and-data-consistency>Deep Dive: Join Strategy and Data Consistency</a></li><li><a href=#handling-schema-evolution>Handling Schema Evolution</a></li><li><a href=#deduplication-techniques>Deduplication Techniques</a></li><li><a href=#recovery-in-case-of-partial-failure>Recovery in Case of Partial Failure</a></li></ol></li><li><a href=#backup-strategy-abstraction-because-mistakes-happen>Backup Strategy Abstraction: Because Mistakes Happen</a><ol><li><a href=#trade-offs-between-snapshot-and-versioning-based-backups>Trade-offs Between Snapshot and Versioning-Based Backups</a></li><li><a href=#cost-and-performance-considerations-across-clouds>Cost and Performance Considerations Across Clouds</a></li><li><a href=#restore-strategies>Restore Strategies</a></li></ol></li><li><a href=#auditrecord-pattern-observability-by-design>AuditRecord Pattern: Observability by Design</a><ol><li><a href=#schema-for-observability-events>Schema for Observability Events</a></li><li><a href=#wiring-into-pubsub-and-stackdriver>Wiring into Pub/Sub and Stackdriver</a></li><li><a href=#real-dashboards-built-with-this-data>Real Dashboards Built with This Data</a></li></ol></li><li><a href=#modular-api-composition-with-dsl>Modular API Composition with DSL</a></li><li><a href=#real-dsl-flows-batch-mode-example>Real DSL Flows: Batch Mode Example</a><ol><li><a href=#streaming-mode-example>Streaming Mode Example</a></li><li><a href=#benefits-of-this-dsl>Benefits of This DSL</a></li></ol></li><li><a href=#real-world-deployment-examples>Real-World Deployment Examples</a><ol><li><a href=#case-study-1-multi-region-event-lake-with-partition-pruning>Case Study 1: Multi-Region Event Lake with Partition Pruning</a></li><li><a href=#case-study-2-cdc--backup-in-e-commerce-pipeline>Case Study 2: CDC + Backup in E-commerce Pipeline</a></li></ol></li><li><a href=#mocked-use-case--example-output>Mocked Use Case + Example Output</a><ol><li><a href=#file-level-diff-logic>File-Level Diff Logic</a></li><li><a href=#performance-tuning>Performance Tuning</a></li></ol></li><li><a href=#platform-metrics-saved>Platform Metrics Saved</a><ol><li><a href=#developer-feedback-and-onboarding-benefits>Developer Feedback and Onboarding Benefits</a></li><li><a href=#sre-simplifications>SRE Simplifications</a></li></ol></li><li><a href=#whats-next>What‚Äôs Next?</a></li><li><a href=#final-links--wrap-up>Final Links & Wrap-Up</a></li><li><a href=#sdk-internals--gcp-interop>SDK Internals & GCP Interop</a><ol><li><a href=#dataproc-tips>Dataproc Tips</a></li><li><a href=#bigquery-integration>BigQuery Integration</a></li><li><a href=#gcs-snapshot-performance>GCS Snapshot Performance</a></li><li><a href=#pubsub-as-orchestration>Pub/Sub as Orchestration</a></li></ol></li></ol></nav></aside><blockquote><p>‚ÄúWhen scale knocks, APIs shouldn‚Äôt break. They should smile back.‚Äù</p></blockquote><hr><h1 id=-intro--data-engineering-at-scale-the-real-deal>üß† Intro ‚Äì Data Engineering at Scale: The Real Deal</h1><p>Forget the buzzwords and ‚Äúintro to Spark‚Äù tutorials. Real Data Engineering at scale is a beast that chews through na√Øve
assumptions, burns your cloud credits, and laughs at your YAML configs.</p><p>This blog isn‚Äôt a primer. It‚Äôs a battle-tested story‚Äîhow we built a cloud-native SDK in Scala on GCP to tame petabyte
lakes, orchestrate CDC without ACID, and whisper to partitions so you only scan what <em>actually</em> changed.</p><p>You‚Äôll get:</p><ul><li>The madness behind scale and why ‚Äúread the whole table‚Äù is a joke</li><li>Our SDK philosophy: more than helpers, a modular, composable toolkit</li><li>The magic of <code>getAffectedPartitions</code> and CDC without UPDATEs</li><li>Backup abstractions and audit records for observability</li><li>Real-world deployments, metrics saved, and what‚Äôs next</li></ul><hr><h2 id=the-madness-of-scale-why-just-read-everything-is-dead>The Madness of Scale: Why ‚ÄúJust Read Everything‚Äù Is Dead</h2><p>Imagine managing a multi-petabyte data lake spread across regions, powered by Delta and Hive tables. Teams are deploying
DAGs daily, some buggy, some brilliant, but all hungry for data freshness.</p><p>The na√Øve approach? Read everything every time.<br>Reality? Your cloud bill explodes, jobs time out, and devs lose faith.</p><h3 id=the-real-world-pain-symptoms-of-scale-gone-wrong>The Real-World Pain: Symptoms of Scale Gone Wrong</h3><p>At petabyte scale, na√Øve CDC logic quickly reveals itself as a ticking time bomb. Here‚Äôs what we saw in the trenches:</p><ul><li><p><strong>Exploding Cloud Bills:</strong> Running full table scans daily on multi-terabyte datasets meant tens of thousands of
dollars in GCS egress and BigQuery query costs. The cost curve was exponential, not linear.</p></li><li><p><strong>Job Failures & Timeouts:</strong> Spark jobs reading entire partitions would fail due to executor OOMs or cluster
preemption. DAGs timed out regularly, causing cascading failures downstream.</p></li><li><p><strong>Inefficient Resource Usage:</strong> Cluster resources were wasted scanning unchanged data, leaving little room for real
transformations or analytics workloads.</p></li><li><p><strong>Developer Frustration:</strong> Teams spent more time debugging flaky pipelines than delivering features. Onboarding new
engineers became a nightmare due to complex, brittle codebases.</p></li></ul><h3 id=common-anti-patterns-in-na√Øve-cdc-logic>Common Anti-patterns in Na√Øve CDC Logic</h3><ul><li><p><strong>Full Table or Partition Scans:</strong> No filtering, just brute force reading of entire datasets every run.</p></li><li><p><strong>Relying on Timestamps in Data:</strong> Using ingestion timestamps as change indicators is brittle and often inaccurate.</p></li><li><p><strong>Overusing MERGE Statements:</strong> Blindly merging entire tables without partition pruning leads to massive shuffle and
compute costs.</p></li><li><p><strong>Ignoring Cloud Storage Semantics:</strong> Not accounting for eventual consistency or file listing delays causing
inconsistent snapshots.</p></li><li><p><strong>Hardcoding Paths and Schemas:</strong> Making pipelines fragile and hard to maintain.</p></li></ul><h3 id=what-we-needed-discipline-encoded-as-code>What We Needed: Discipline Encoded as Code</h3><p>We realized that at scale, data engineering is a software engineering challenge first and foremost. We needed an SDK
that:</p><ul><li><p><strong>Understands Scale:</strong> Knows how to avoid scanning everything.</p></li><li><p><strong>Whispers to Partitions:</strong> Detects changes precisely.</p></li><li><p><strong>Is Cloud-Native:</strong> Leverages GCP features without locking in.</p></li><li><p><strong>Is Modular and Testable:</strong> So teams can trust and extend it.</p></li></ul><p>This was the genesis of our cloud-native, Scala-based SDK.</p><hr><h2 id=sdk-philosophy-beyond-utilities-into-a-modular-toolkit>SDK Philosophy: Beyond Utilities, Into a Modular Toolkit</h2><p>Most SDKs are glorified helper libraries. Ours is different.</p><p>We designed it to be:</p><ul><li><strong>Modular:</strong> Independent components that compose cleanly</li><li><strong>Composable:</strong> DSL-style chaining that reads like a story</li><li><strong>Cloud-native:</strong> Abstracted from vendor specifics but optimized for GCP</li><li><strong>Observability-first:</strong> Audit records baked in, not bolted on</li></ul><h3 id=architectural-decisions-why-modularity>Architectural Decisions: Why Modularity?</h3><p>Modularity was key to managing complexity and enabling reuse. By breaking down the SDK into small, focused traits and
classes, we could:</p><ul><li><p><strong>Easily Swap Implementations:</strong> For example, swapping GCS with S3 or Azure Blob Storage without rewriting logic.</p></li><li><p><strong>Improve Testability:</strong> Smaller components are easier to unit test and mock.</p></li><li><p><strong>Enable Parallel Development:</strong> Different teams could own different modules.</p></li><li><p><strong>Simplify Maintenance:</strong> Bugs and enhancements are isolated.</p></li></ul><h3 id=trait-based-abstractions-and-avoiding-implicits>Trait-Based Abstractions and Avoiding Implicits</h3><p>We chose explicit trait-based abstractions over Scala implicits to:</p><ul><li><p><strong>Improve Readability:</strong> Explicit dependencies are easier to track.</p></li><li><p><strong>Avoid Magic:</strong> Reducing cognitive overhead for new contributors.</p></li><li><p><strong>Enable Better Compile-Time Checks:</strong> Traits enforce contracts clearly.</p></li></ul><h3 id=sdk-lifecycle-publishing-and-versioning>SDK Lifecycle: Publishing and Versioning</h3><p>Our SDK follows a strict lifecycle:</p><ul><li><p><strong>Semantic Versioning:</strong> Major versions introduce breaking changes, minor versions add features, patches fix bugs.</p></li><li><p><strong>Automated Publishing:</strong> CI/CD pipelines publish artifacts to Maven Central on successful builds.</p></li><li><p><strong>Backward Compatibility:</strong> We maintain compatibility for at least two major versions to avoid breaking users.</p></li><li><p><strong>Documentation & Changelogs:</strong> Every release is accompanied by detailed docs and migration guides.</p></li></ul><h3 id=testability-and-continuous-integration>Testability and Continuous Integration</h3><ul><li><p><strong>Unit Tests:</strong> Cover each module in isolation.</p></li><li><p><strong>Integration Tests:</strong> Run on ephemeral GCP resources to validate end-to-end flows.</p></li><li><p><strong>Performance Benchmarks:</strong> Monitor SDK performance regressions.</p></li><li><p><strong>Static Analysis:</strong> Enforce code quality and style.</p></li></ul><p>This philosophy ensures the SDK is robust, maintainable, and scalable in both code and usage.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>+-------------------------+
</span></span><span class=line><span class=cl>|     CloudStorage        |
</span></span><span class=line><span class=cl>+-------------------------+
</span></span><span class=line><span class=cl>             |
</span></span><span class=line><span class=cl>             v
</span></span><span class=line><span class=cl>+-------------------------+
</span></span><span class=line><span class=cl>|  AffectedPartitions     |
</span></span><span class=line><span class=cl>+-------------------------+
</span></span><span class=line><span class=cl>             |
</span></span><span class=line><span class=cl>             v
</span></span><span class=line><span class=cl>+-------------------------+
</span></span><span class=line><span class=cl>|      CDC Merge SCD1     |
</span></span><span class=line><span class=cl>+-------------------------+
</span></span><span class=line><span class=cl>             |
</span></span><span class=line><span class=cl>             v
</span></span><span class=line><span class=cl>+-------------------------+
</span></span><span class=line><span class=cl>|      Backup &amp; Audit     |
</span></span><span class=line><span class=cl>+-------------------------+
</span></span></code></pre></td></tr></table></div></div><hr><h2 id=partition-whispering-getaffectedpartitions>Partition Whispering: <code>getAffectedPartitions</code></h2><p>The million-dollar question:</p><blockquote><p>‚ÄúWhich partitions actually changed?‚Äù</p></blockquote><p>Without ACID or full snapshots, we can‚Äôt just ‚Äúdiff tables.‚Äù We <em>whisper</em> to partitions by comparing snapshots of file
metadata.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=k>val</span> <span class=n>oldSnapshot</span> <span class=k>=</span> <span class=n>cloudStorage</span><span class=o>.</span><span class=n>listFiles</span><span class=o>(</span><span class=n>checkpointPath</span><span class=o>)</span>
</span></span><span class=line><span class=cl><span class=k>val</span> <span class=n>newSnapshot</span> <span class=k>=</span> <span class=n>cloudStorage</span><span class=o>.</span><span class=n>listFiles</span><span class=o>(</span><span class=n>currentPath</span><span class=o>)</span>
</span></span><span class=line><span class=cl><span class=k>val</span> <span class=n>deltaFiles</span> <span class=k>=</span> <span class=n>diff</span><span class=o>(</span><span class=n>oldSnapshot</span><span class=o>,</span> <span class=n>newSnapshot</span><span class=o>)</span>
</span></span><span class=line><span class=cl><span class=k>val</span> <span class=n>affectedPartitions</span> <span class=k>=</span> <span class=n>extractPartitions</span><span class=o>(</span><span class=n>deltaFiles</span><span class=o>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=metadata-snapshotting-capturing-the-state-of-the-lake>Metadata Snapshotting: Capturing the State of the Lake</h3><p>Our snapshotting involves capturing file metadata such as:</p><ul><li>File path</li><li>Size</li><li>Last modified timestamp</li><li>Partition keys parsed from path</li></ul><p>We store snapshots as compact manifests (e.g., Parquet or JSON files) to avoid expensive repeated listings.</p><h3 id=cloud-specific-quirks-gcs-eventual-consistency-and-more>Cloud-Specific Quirks: GCS Eventual Consistency and More</h3><ul><li><p><strong>Eventual Consistency:</strong> GCS listings may lag behind writes for seconds to minutes. We mitigate this by:</p><ul><li><p>Using versioned manifests to snapshot state at a point in time.</p></li><li><p>Adding retries and backoff in listings.</p></li></ul></li><li><p><strong>Listing Limits:</strong> GCS limits the number of files returned per request. We paginate and parallelize listings.</p></li><li><p><strong>IAM Permissions:</strong> Fine-grained IAM roles are necessary to list and read files efficiently.</p></li></ul><h3 id=partition-extraction-strategies>Partition Extraction Strategies</h3><p>Extracting partitions from file paths is non-trivial:</p><ul><li><p><strong>Hierarchical Paths:</strong> e.g., <code>gs://bucket/events/dt=2025-07-18/region=us/file.parquet</code></p></li><li><p><strong>Dynamic Partition Keys:</strong> Some datasets have varying partition keys.</p></li><li><p><strong>Schema Evolution:</strong> New partitions or keys may appear over time.</p></li></ul><p>We use configurable regex-based parsers and fallback heuristics to reliably extract partitions.</p><p><strong>Flow Diagram:</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>+-------------+      +-------------+      +-----------------+      +-----------------+
</span></span><span class=line><span class=cl>| prevFiles[] | ---&gt; | currFiles[] | ---&gt; | changedFiles[]  | ---&gt; | affectedParts[] |
</span></span><span class=line><span class=cl>+-------------+      +-------------+      +-----------------+      +-----------------+
</span></span><span class=line><span class=cl>        |                  |                    |                        |
</span></span><span class=line><span class=cl>        |                  |                    |                        |
</span></span><span class=line><span class=cl>   (snapshot)          (snapshot)          (diff by path &amp; ts)      (extract partition keys)
</span></span></code></pre></td></tr></table></div></div><p>Our <code>CloudStorage</code> trait abstracts GCS, S3, and Azure, making this logic cloud-agnostic yet performant.</p><hr><h2 id=cdc-without-acid-performdelta>CDC Without ACID: <code>performDelta</code></h2><p>No UPDATEs. No MERGE statements on raw Parquet.</p><p>We fake CDC (SCD Type 1) by joining base and incoming datasets, applying ‚Äúnewer wins‚Äù logic, and overwriting partitions
atomically.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=k>val</span> <span class=n>output</span> <span class=k>=</span> <span class=n>base</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>join</span><span class=o>(</span><span class=n>newData</span><span class=o>,</span> <span class=nc>Seq</span><span class=o>(</span><span class=s>&#34;id&#34;</span><span class=o>),</span> <span class=s>&#34;outer&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>map</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>case</span> <span class=o>(</span><span class=nc>Some</span><span class=o>(</span><span class=n>old</span><span class=o>),</span> <span class=nc>Some</span><span class=o>(</span> <span class=k>new</span><span class=o>)</span> <span class=o>)</span> <span class=k>=&gt;</span> <span class=n>newerWins</span><span class=o>(</span><span class=n>old</span><span class=o>,</span> <span class=k>new</span><span class=o>)</span>
</span></span><span class=line><span class=cl>    <span class=k>case</span> <span class=o>(</span><span class=nc>None</span><span class=o>,</span> <span class=nc>Some</span><span class=o>(</span><span class=k>new</span><span class=o>))</span>
</span></span><span class=line><span class=cl>    <span class=k>=&gt;</span> <span class=k>new</span>
</span></span><span class=line><span class=cl>    <span class=k>case</span> <span class=o>(</span><span class=nc>Some</span><span class=o>(</span><span class=n>old</span><span class=o>),</span> <span class=nc>None</span><span class=o>)</span>
</span></span><span class=line><span class=cl>    <span class=k>=&gt;</span> <span class=n>old</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=deep-dive-join-strategy-and-data-consistency>Deep Dive: Join Strategy and Data Consistency</h3><ul><li><p><strong>Outer Join:</strong> Ensures all records from both base and new datasets are considered.</p></li><li><p><strong>Newer Wins:</strong> Based on timestamps or version columns, we pick the latest record.</p></li><li><p><strong>Handling Deletes:</strong> We treat absence in new data as retention of old data; explicit deletes require separate logic.</p></li></ul><h3 id=handling-schema-evolution>Handling Schema Evolution</h3><ul><li><p><strong>Schema Merging:</strong> We allow new columns in incoming data and merge schemas dynamically.</p></li><li><p><strong>Type Compatibility:</strong> We apply type promotion where safe (e.g., int ‚Üí long).</p></li><li><p><strong>Validation:</strong> Fail fast if incompatible schema changes are detected.</p></li></ul><h3 id=deduplication-techniques>Deduplication Techniques</h3><ul><li><p><strong>Within Incoming Data:</strong> We deduplicate incoming records by primary key and timestamp.</p></li><li><p><strong>Across Batches:</strong> Our partition-level CDC ensures no overlapping writes.</p></li><li><p><strong>Using Watermarks:</strong> For streaming data, we use event-time watermarks to delay processing and handle late data.</p></li></ul><h3 id=recovery-in-case-of-partial-failure>Recovery in Case of Partial Failure</h3><ul><li><p><strong>Atomic Writes:</strong> We write to temporary locations and atomically swap partitions.</p></li><li><p><strong>Backup Before Overwrite:</strong> See next section.</p></li><li><p><strong>Idempotency:</strong> CDC operations are designed to be idempotent, allowing safe retries.</p></li><li><p><strong>Audit Records:</strong> Capture operation status and errors for troubleshooting.</p></li></ul><hr><h2 id=backup-strategy-abstraction-because-mistakes-happen>Backup Strategy Abstraction: Because Mistakes Happen</h2><p>Before overwriting partitions, we back up existing data. But backup strategies vary:</p><ul><li>Full snapshot copies</li><li>Incremental backups</li><li>Cloud-native versioning (GCS object versioning)</li></ul><p>Our SDK exposes a <code>BackupStrategy</code> trait:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=k>trait</span> <span class=nc>BackupStrategy</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=n>backup</span><span class=o>(</span><span class=n>partitionPath</span><span class=k>:</span> <span class=kt>String</span><span class=o>)</span><span class=k>:</span> <span class=kt>Unit</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=trade-offs-between-snapshot-and-versioning-based-backups>Trade-offs Between Snapshot and Versioning-Based Backups</h3><table><thead><tr><th>Backup Type</th><th>Pros</th><th>Cons</th></tr></thead><tbody><tr><td>Full Snapshot Copy</td><td>Simple, easy to restore</td><td>High storage cost, slow</td></tr><tr><td>Incremental Backup</td><td>Efficient storage, faster</td><td>Complex restore logic</td></tr><tr><td>Cloud Versioning</td><td>No extra storage, automatic</td><td>Limited to supported clouds, cost depends on versioning policy</td></tr></tbody></table><h3 id=cost-and-performance-considerations-across-clouds>Cost and Performance Considerations Across Clouds</h3><ul><li><p><strong>GCS:</strong> Versioning is cheap and native, but listing versions can be slow.</p></li><li><p><strong>S3:</strong> Supports versioning with lifecycle policies.</p></li><li><p><strong>Azure Blob:</strong> Snapshots are supported but have different semantics.</p></li></ul><p>Backup frequency and retention policies are tuned to balance cost and recovery SLAs.</p><h3 id=restore-strategies>Restore Strategies</h3><ul><li><p><strong>Point-in-Time Restore:</strong> Revert partitions to a known good snapshot.</p></li><li><p><strong>Selective Restore:</strong> Restore only corrupted or failed partitions.</p></li><li><p><strong>Automated Rollbacks:</strong> Triggered by audit failures or alerts.</p></li></ul><hr><h2 id=auditrecord-pattern-observability-by-design>AuditRecord Pattern: Observability by Design</h2><p>Every CDC operation emits an <code>AuditRecord</code> capturing:</p><ul><li>Timestamps</li><li>Partition keys</li><li>Number of records processed</li><li>Errors and retries</li></ul><p>This pattern lives in the SDK core, enabling:</p><ul><li>Monitoring dashboards</li><li>Automated alerts</li><li>Post-mortem analysis</li></ul><p>Example snippet:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=k>case</span> <span class=k>class</span> <span class=nc>AuditRecord</span><span class=o>(</span>
</span></span><span class=line><span class=cl>                        <span class=n>jobId</span><span class=k>:</span> <span class=kt>String</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>partition</span><span class=k>:</span> <span class=kt>Map</span><span class=o>[</span><span class=kt>String</span>, <span class=kt>String</span><span class=o>],</span>
</span></span><span class=line><span class=cl>                        <span class=n>processedCount</span><span class=k>:</span> <span class=kt>Long</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>timestamp</span><span class=k>:</span> <span class=kt>Instant</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>status</span><span class=k>:</span> <span class=kt>String</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>errorMessage</span><span class=k>:</span> <span class=kt>Option</span><span class=o>[</span><span class=kt>String</span><span class=o>]</span> <span class=k>=</span> <span class=nc>None</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>retries</span><span class=k>:</span> <span class=kt>Int</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>                      <span class=o>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=schema-for-observability-events>Schema for Observability Events</h3><p>Our audit schema includes:</p><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td>jobId</td><td>String</td><td>Unique job identifier</td></tr><tr><td>partition</td><td>Map[String, String]</td><td>Partition keys and values</td></tr><tr><td>processedCount</td><td>Long</td><td>Number of records processed</td></tr><tr><td>timestamp</td><td>Instant</td><td>Operation timestamp</td></tr><tr><td>status</td><td>String</td><td>Success, Failed, Retried</td></tr><tr><td>errorMessage</td><td>Option[String]</td><td>Error details if any</td></tr><tr><td>retries</td><td>Int</td><td>Number of retry attempts</td></tr></tbody></table><h3 id=wiring-into-pubsub-and-stackdriver>Wiring into Pub/Sub and Stackdriver</h3><ul><li><p>AuditRecords are serialized as JSON and published to a dedicated Pub/Sub topic.</p></li><li><p>Stackdriver (Cloud Logging) sinks subscribe to the topic for real-time log ingestion.</p></li><li><p>Alerts are configured on error rates and latency anomalies.</p></li></ul><h3 id=real-dashboards-built-with-this-data>Real Dashboards Built with This Data</h3><ul><li><p><strong>CDC Health Dashboard:</strong> Success/failure rates per partition and job.</p></li><li><p><strong>Latency Monitoring:</strong> Time between data arrival and CDC completion.</p></li><li><p><strong>Cost Attribution:</strong> Correlate audit events with resource usage.</p></li><li><p><strong>On-call Alerts:</strong> PagerDuty integration for critical failures.</p></li></ul><hr><h2 id=modular-api-composition-with-dsl>Modular API Composition with DSL</h2><p>Our SDK shines in its expressive DSL:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=nc>AffectedPartitions</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>on</span><span class=o>(</span><span class=s>&#34;gs://bucket/events&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>since</span><span class=o>(</span><span class=s>&#34;2025-07-17&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>identify</span><span class=o>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nc>CdcType1</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>on</span><span class=o>(</span><span class=s>&#34;gs://incoming&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>merge</span><span class=o>()</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>into</span><span class=o>(</span><span class=s>&#34;bigquery.customers&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>withBackup</span><span class=o>(</span><span class=n>backupStrategy</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>audit</span><span class=o>()</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=real-dsl-flows-batch-mode-example>Real DSL Flows: Batch Mode Example</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=k>val</span> <span class=n>partitions</span> <span class=k>=</span> <span class=nc>AffectedPartitions</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>on</span><span class=o>(</span><span class=s>&#34;gs://my-bucket/events&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>since</span><span class=o>(</span><span class=s>&#34;2025-07-01&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>identify</span><span class=o>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nc>CdcType1</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>on</span><span class=o>(</span><span class=s>&#34;gs://my-bucket/incoming&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>merge</span><span class=o>()</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>into</span><span class=o>(</span><span class=s>&#34;bigquery.my_dataset.customers&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>withBackup</span><span class=o>(</span><span class=n>snapshotBackup</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>audit</span><span class=o>()</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>run</span><span class=o>()</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=streaming-mode-example>Streaming Mode Example</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=nc>StreamingCdcType1</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>source</span><span class=o>(</span><span class=s>&#34;gs://streaming-bucket/events&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>withWatermark</span><span class=o>(</span><span class=s>&#34;event_time&#34;</span><span class=o>,</span> <span class=s>&#34;10 minutes&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>merge</span><span class=o>()</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>into</span><span class=o>(</span><span class=s>&#34;bigquery.streaming.customers&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>withBackup</span><span class=o>(</span><span class=n>versioningBackup</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>audit</span><span class=o>()</span>
</span></span><span class=line><span class=cl>  <span class=o>.</span><span class=n>start</span><span class=o>()</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><p>Supports continuous processing with checkpointing.</p></li><li><p>Handles late data and retries transparently.</p></li></ul><h3 id=benefits-of-this-dsl>Benefits of This DSL</h3><ul><li><p><strong>Declarative:</strong> Users focus on <em>what</em> instead of <em>how</em>.</p></li><li><p><strong>Composable:</strong> Each step returns a builder for chaining.</p></li><li><p><strong>Extensible:</strong> New modules plug in without breaking existing flows.</p></li></ul><hr><h2 id=real-world-deployment-examples>Real-World Deployment Examples</h2><p>Our SDK powers:</p><ul><li>A multi-region event lake with daily partition detection</li><li>CDC pipelines merging streaming and batch data</li><li>Backup and audit layers integrated with GCP Scheduler and Pub/Sub</li></ul><pre tabindex=0><code class=language-diagram data-lang=diagram>+------------+   +-------------+   +----------------+   +------------+
| GCS Source | ‚Üí | Dataproc Job| ‚Üí | SDK CDC Logic  | ‚Üí | BigQuery   |
+------------+   +-------------+   +----------------+   +------------+
</code></pre><h3 id=case-study-1-multi-region-event-lake-with-partition-pruning>Case Study 1: Multi-Region Event Lake with Partition Pruning</h3><h4 id=background>Background</h4><p>A global e-commerce company ingests terabytes of event data daily from multiple regions. Each region writes to its own
GCS bucket partitioned by date and region.</p><h4 id=challenge>Challenge</h4><ul><li><p>Running full scans over all regions daily was unsustainable.</p></li><li><p>Data freshness SLA was tight (under 30 minutes).</p></li></ul><h4 id=solution>Solution</h4><ul><li><p>Used <code>AffectedPartitions</code> to detect changed partitions per region.</p></li><li><p>Scheduled Dataproc jobs to process only affected partitions.</p></li><li><p>CDC logic merged event data into BigQuery partitioned tables.</p></li><li><p>Backup and audit layers ensured recoverability and observability.</p></li></ul><h4 id=results>Results</h4><ul><li><p>Reduced data scanned by 95%.</p></li><li><p>Cut daily processing time from 3 hours to 15 minutes.</p></li><li><p>Cloud costs dropped by 80%.</p></li><li><p>Improved developer confidence with clear audit trails.</p></li></ul><h3 id=case-study-2-cdc--backup-in-e-commerce-pipeline>Case Study 2: CDC + Backup in E-commerce Pipeline</h3><h4 id=background-1>Background</h4><p>An online retailer processes customer and order data with frequent updates and corrections.</p><h4 id=challenge-1>Challenge</h4><ul><li><p>Need SCD Type 1 CDC without transactional support.</p></li><li><p>Backup required to protect against accidental overwrites.</p></li><li><p>Schema evolution was frequent due to product catalog changes.</p></li></ul><h4 id=solution-1>Solution</h4><ul><li><p>Leveraged <code>CdcType1</code> with deduplication and newer-wins logic.</p></li><li><p>Implemented <code>BackupStrategy</code> with incremental backups on GCS.</p></li><li><p>Integrated audit events into Pub/Sub for monitoring.</p></li><li><p>Used schema merging and validation to handle evolution.</p></li></ul><h4 id=results-1>Results</h4><ul><li><p>Zero data loss incidents after deployment.</p></li><li><p>Faster recovery from pipeline errors.</p></li><li><p>Clear visibility into data freshness and processing status.</p></li></ul><hr><h2 id=mocked-use-case--example-output>Mocked Use Case + Example Output</h2><p><strong>Scenario:</strong> Incoming data for <code>dt=2025-07-18 / region=us</code> adds new files.</p><p><strong>Affected partitions:</strong></p><table><thead><tr><th>Partition Key</th><th>Value</th></tr></thead><tbody><tr><td>dt</td><td>2025-07-18</td></tr><tr><td>region</td><td>us</td></tr></tbody></table><p><strong>CDC merge result:</strong></p><table><thead><tr><th>ID</th><th>Base Name</th><th>Incoming Name</th><th>Final Name</th></tr></thead><tbody><tr><td>101</td><td>John</td><td>Jonny</td><td>Jonny</td></tr><tr><td>102</td><td>Alice</td><td>-</td><td>Alice</td></tr><tr><td>103</td><td>-</td><td>Bob</td><td>Bob</td></tr></tbody></table><h3 id=file-level-diff-logic>File-Level Diff Logic</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=k>def</span> <span class=n>diff</span><span class=o>(</span><span class=n>oldFiles</span><span class=k>:</span> <span class=kt>List</span><span class=o>[</span><span class=kt>FileMeta</span><span class=o>],</span> <span class=n>newFiles</span><span class=k>:</span> <span class=kt>List</span><span class=o>[</span><span class=kt>FileMeta</span><span class=o>])</span><span class=k>:</span> <span class=kt>List</span><span class=o>[</span><span class=kt>FileMeta</span><span class=o>]</span> <span class=k>=</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=k>val</span> <span class=n>oldSet</span> <span class=k>=</span> <span class=n>oldFiles</span><span class=o>.</span><span class=n>map</span><span class=o>(</span><span class=n>f</span> <span class=k>=&gt;</span> <span class=o>(</span><span class=n>f</span><span class=o>.</span><span class=n>path</span><span class=o>,</span> <span class=n>f</span><span class=o>.</span><span class=n>lastModified</span><span class=o>)).</span><span class=n>toSet</span>
</span></span><span class=line><span class=cl>  <span class=k>val</span> <span class=n>newSet</span> <span class=k>=</span> <span class=n>newFiles</span><span class=o>.</span><span class=n>map</span><span class=o>(</span><span class=n>f</span> <span class=k>=&gt;</span> <span class=o>(</span><span class=n>f</span><span class=o>.</span><span class=n>path</span><span class=o>,</span> <span class=n>f</span><span class=o>.</span><span class=n>lastModified</span><span class=o>)).</span><span class=n>toSet</span>
</span></span><span class=line><span class=cl>  <span class=k>val</span> <span class=n>changed</span> <span class=k>=</span> <span class=n>newSet</span><span class=o>.</span><span class=n>diff</span><span class=o>(</span><span class=n>oldSet</span><span class=o>).</span><span class=n>map</span> <span class=o>{</span> <span class=k>case</span> <span class=o>(</span><span class=n>path</span><span class=o>,</span> <span class=k>_</span><span class=o>)</span> <span class=k>=&gt;</span>
</span></span><span class=line><span class=cl>    <span class=n>newFiles</span><span class=o>.</span><span class=n>find</span><span class=o>(</span><span class=k>_</span><span class=o>.</span><span class=n>path</span> <span class=o>==</span> <span class=n>path</span><span class=o>).</span><span class=n>get</span>
</span></span><span class=line><span class=cl>  <span class=o>}</span>
</span></span><span class=line><span class=cl>  <span class=n>changed</span><span class=o>.</span><span class=n>toList</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><p>Compares file paths and modification timestamps.</p></li><li><p>Identifies new or updated files.</p></li><li><p>Efficient with parallelized metadata listing.</p></li></ul><h3 id=performance-tuning>Performance Tuning</h3><ul><li><p>Parallelize file listings with thread pools.</p></li><li><p>Cache snapshots in memory and storage.</p></li><li><p>Use bloom filters for large file sets.</p></li><li><p>Batch partition extraction to reduce overhead.</p></li></ul><hr><h2 id=platform-metrics-saved>Platform Metrics Saved</h2><table><thead><tr><th>Metric</th><th>Before</th><th>After</th></tr></thead><tbody><tr><td>Runtime</td><td>18 min</td><td>2.3 min</td></tr><tr><td>Files scanned</td><td>~4,000</td><td>~120</td></tr><tr><td>BigQuery Costs</td><td>$$$</td><td>$</td></tr><tr><td>Developer Onboarding Time</td><td>3 weeks</td><td>3 days</td></tr><tr><td>Code Reuse</td><td>20%</td><td>90%</td></tr></tbody></table><h3 id=developer-feedback-and-onboarding-benefits>Developer Feedback and Onboarding Benefits</h3><ul><li><p>New engineers ramped up faster due to clear abstractions.</p></li><li><p>Reduced cognitive load by hiding complex cloud interactions.</p></li><li><p>Improved collaboration with shared SDK ownership.</p></li></ul><h3 id=sre-simplifications>SRE Simplifications</h3><ul><li><p>Reduced alert noise with better failure isolation.</p></li><li><p>Faster incident resolution with audit logs.</p></li><li><p>Predictable resource usage and cost forecasting.</p></li></ul><hr><h2 id=whats-next>What‚Äôs Next?</h2><ul><li><p><strong>SCD Type 2:</strong> Adding history tracking and versioning for auditability and compliance.</p></li><li><p><strong>Open Source Drop:</strong> Sharing the SDK with the community under Apache 2.0 license.</p></li><li><p><strong>CLI Interface:</strong> For non-Scala users and easier adoption in ad-hoc workflows.</p></li><li><p><strong>GDE Application:</strong> Sharing knowledge and growing the ecosystem with Google Developer Experts.</p></li><li><p><strong>SDK Versioning Enhancements:</strong> Semantic versioning enforcement and automated migration tooling.</p></li><li><p><strong>Open-Source Compliance Setup:</strong> License scanning, contributor guidelines, and community governance.</p></li></ul><hr><h2 id=final-links--wrap-up>Final Links & Wrap-Up</h2><ul><li><a href=https://cloud.google.com/dataproc target=_blank rel="nofollow noopener noreferrer">Dataproc Docs</a></li><li><a href=https://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax#merge_statement target=_blank rel="nofollow noopener noreferrer">BigQuery Merge Syntax</a></li><li><a href=https://cloud.google.com/ target=_blank rel="nofollow noopener noreferrer">Scala on GCP</a></li></ul><hr><blockquote><p>This is the blog I <em>wish</em> I had read when starting out.<br>Not just an intro, but a blueprint for building scalable, maintainable, cloud-native data engineering workflows.</p></blockquote><hr><div class=admonition><strong></strong><div class=admonition-content>*Want to dive deeper?* The SDK abstractions, design docs, and example code snippets live in
our [GitHub repo](https://github.com/yourorg/yourrepo).</div></div><hr><pre class=mermaid>
  classDiagram
  note &#34;Low-level SDK Architecture&#34;
  class Partition {
    +key: String
    +value: String
  }
  class CloudStorage {
    +listFiles(path: String): List[FileMeta]
  }
  class AffectedPartitions {
    +identify(): List[Partition]
  }
  class CdcType1 {
    +merge(): Unit
  }
</pre><hr><div class=mermaid>graph TD
A[CloudStorage] --> B[AffectedPartitions]
B --> C[CdcType1 Merge]
C --> D[Backup & Audit]</div><hr><h2 id=sdk-internals--gcp-interop>SDK Internals & GCP Interop</h2><h3 id=dataproc-tips>Dataproc Tips</h3><ul><li><p><strong>Executor Memory Tuning:</strong> Optimize executor heap and off-heap memory to prevent OOMs during large joins.</p></li><li><p><strong>Shuffle Behavior for Large Joins:</strong> Use shuffle partitions tuning and adaptive query execution to balance load.</p></li><li><p><strong>GCS Connector Optimization:</strong> Enable caching and configure retry policies to mitigate GCS eventual consistency.</p></li></ul><h3 id=bigquery-integration>BigQuery Integration</h3><ul><li><p><strong>Partition Pruning:</strong> Ensure merge queries include partition filters to reduce scanned data.</p></li><li><p><strong>Merge Statement Caveats:</strong> Avoid merging very large tables without partition filters; monitor query costs closely.</p></li></ul><h3 id=gcs-snapshot-performance>GCS Snapshot Performance</h3><ul><li><p><strong>Metadata Listing Limits:</strong> Use parallel listing and manifest caching to overcome GCS listing throttling.</p></li><li><p><strong>IAM Tricks to Reduce Latency:</strong> Use least-privilege roles and service accounts with minimal permissions for faster
metadata access.</p></li></ul><h3 id=pubsub-as-orchestration>Pub/Sub as Orchestration</h3><ul><li><p><strong>CDC + Notification Wiring:</strong> Publish partition change events to Pub/Sub to trigger downstream jobs.</p></li><li><p><strong>Audit Events to Pipeline Triggers:</strong> Use audit logs in Pub/Sub to automate alerts, retries, and SLA monitoring.</p></li></ul><hr></div><nav class="hide-on-mobile section-nav"><nav id=TableOfContents><ol><li><a href=#the-madness-of-scale-why-just-read-everything-is-dead>The Madness of Scale: Why ‚ÄúJust Read Everything‚Äù Is Dead</a><ol><li><a href=#the-real-world-pain-symptoms-of-scale-gone-wrong>The Real-World Pain: Symptoms of Scale Gone Wrong</a></li><li><a href=#common-anti-patterns-in-na√Øve-cdc-logic>Common Anti-patterns in Na√Øve CDC Logic</a></li><li><a href=#what-we-needed-discipline-encoded-as-code>What We Needed: Discipline Encoded as Code</a></li></ol></li><li><a href=#sdk-philosophy-beyond-utilities-into-a-modular-toolkit>SDK Philosophy: Beyond Utilities, Into a Modular Toolkit</a><ol><li><a href=#architectural-decisions-why-modularity>Architectural Decisions: Why Modularity?</a></li><li><a href=#trait-based-abstractions-and-avoiding-implicits>Trait-Based Abstractions and Avoiding Implicits</a></li><li><a href=#sdk-lifecycle-publishing-and-versioning>SDK Lifecycle: Publishing and Versioning</a></li><li><a href=#testability-and-continuous-integration>Testability and Continuous Integration</a></li></ol></li><li><a href=#partition-whispering-getaffectedpartitions>Partition Whispering: <code>getAffectedPartitions</code></a><ol><li><a href=#metadata-snapshotting-capturing-the-state-of-the-lake>Metadata Snapshotting: Capturing the State of the Lake</a></li><li><a href=#cloud-specific-quirks-gcs-eventual-consistency-and-more>Cloud-Specific Quirks: GCS Eventual Consistency and More</a></li><li><a href=#partition-extraction-strategies>Partition Extraction Strategies</a></li></ol></li><li><a href=#cdc-without-acid-performdelta>CDC Without ACID: <code>performDelta</code></a><ol><li><a href=#deep-dive-join-strategy-and-data-consistency>Deep Dive: Join Strategy and Data Consistency</a></li><li><a href=#handling-schema-evolution>Handling Schema Evolution</a></li><li><a href=#deduplication-techniques>Deduplication Techniques</a></li><li><a href=#recovery-in-case-of-partial-failure>Recovery in Case of Partial Failure</a></li></ol></li><li><a href=#backup-strategy-abstraction-because-mistakes-happen>Backup Strategy Abstraction: Because Mistakes Happen</a><ol><li><a href=#trade-offs-between-snapshot-and-versioning-based-backups>Trade-offs Between Snapshot and Versioning-Based Backups</a></li><li><a href=#cost-and-performance-considerations-across-clouds>Cost and Performance Considerations Across Clouds</a></li><li><a href=#restore-strategies>Restore Strategies</a></li></ol></li><li><a href=#auditrecord-pattern-observability-by-design>AuditRecord Pattern: Observability by Design</a><ol><li><a href=#schema-for-observability-events>Schema for Observability Events</a></li><li><a href=#wiring-into-pubsub-and-stackdriver>Wiring into Pub/Sub and Stackdriver</a></li><li><a href=#real-dashboards-built-with-this-data>Real Dashboards Built with This Data</a></li></ol></li><li><a href=#modular-api-composition-with-dsl>Modular API Composition with DSL</a></li><li><a href=#real-dsl-flows-batch-mode-example>Real DSL Flows: Batch Mode Example</a><ol><li><a href=#streaming-mode-example>Streaming Mode Example</a></li><li><a href=#benefits-of-this-dsl>Benefits of This DSL</a></li></ol></li><li><a href=#real-world-deployment-examples>Real-World Deployment Examples</a><ol><li><a href=#case-study-1-multi-region-event-lake-with-partition-pruning>Case Study 1: Multi-Region Event Lake with Partition Pruning</a></li><li><a href=#case-study-2-cdc--backup-in-e-commerce-pipeline>Case Study 2: CDC + Backup in E-commerce Pipeline</a></li></ol></li><li><a href=#mocked-use-case--example-output>Mocked Use Case + Example Output</a><ol><li><a href=#file-level-diff-logic>File-Level Diff Logic</a></li><li><a href=#performance-tuning>Performance Tuning</a></li></ol></li><li><a href=#platform-metrics-saved>Platform Metrics Saved</a><ol><li><a href=#developer-feedback-and-onboarding-benefits>Developer Feedback and Onboarding Benefits</a></li><li><a href=#sre-simplifications>SRE Simplifications</a></li></ol></li><li><a href=#whats-next>What‚Äôs Next?</a></li><li><a href=#final-links--wrap-up>Final Links & Wrap-Up</a></li><li><a href=#sdk-internals--gcp-interop>SDK Internals & GCP Interop</a><ol><li><a href=#dataproc-tips>Dataproc Tips</a></li><li><a href=#bigquery-integration>BigQuery Integration</a></li><li><a href=#gcs-snapshot-performance>GCS Snapshot Performance</a></li><li><a href=#pubsub-as-orchestration>Pub/Sub as Orchestration</a></li></ol></li></ol></nav></nav></div><div class=post><hr class=footer-separator><div class=tags><ul class=flat><li class=tag-li><a href=../../../tags/gcp>gcp</a></li><li class=tag-li><a href=../../../tags/scala>scala</a></li><li class=tag-li><a href=../../../tags/sdk>sdk</a></li><li class=tag-li><a href=../../../tags/data-engineering>data engineering</a></li><li class=tag-li><a href=../../../tags/cdc>cdc</a></li><li class=tag-li><a href=../../../tags/partitions>partitions</a></li><li class=tag-li><a href=../../../tags/bigquery>bigquery</a></li><li class=tag-li><a href=../../../tags/dataproc>dataproc</a></li><li class=tag-li><a href=../../../tags/cloud>cloud</a></li></ul></div><div class=back><a href=https://github.com/vim89/vitthalmirji.com/blob/master/content/posts/2025/07/slicing-time-at-scale/index.md title=github><i data-feather=github></i> Edit this on GitHub</a></div><div class=back><a href=https://vitthalmirji.com/><span aria-hidden=true>‚Üê Back</span></a></div><div class=back>Next time, we'll talk about <i>"10 Reasons why gcc SHOULD be re-written in JavaScript - You won't believe #8!"</i></div></div></div><div class="footer wrapper"><nav class=nav><div>2025 ¬© Copyright notice</div></nav></div><script>feather.replace()</script><script type=module>
	import mermaid from "https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs";

	const getMermaidTheme = () => {
		const savedScheme = localStorage.getItem('scheme');
		if (savedScheme) {
			return savedScheme === 'dark' ? 'dark' : 'default';
		}
		return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
	};

	mermaid.initialize({
		startOnLoad: true,
		theme: getMermaidTheme()
	});

	const applyTheme = () => {
		const newTheme = getMermaidTheme();
		mermaid.initialize({
			startOnLoad: true,
			theme: newTheme
		});
	};

	window.addEventListener('storage', (event) => {
		if (event.key === 'scheme') {
			applyTheme();
		}
	});

	window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', applyTheme);
</script><script>document.querySelectorAll("pre code").forEach(e=>{const t=document.createElement("button");t.innerText="üìã",t.onclick=()=>{navigator.clipboard.writeText(e.innerText),t.innerText="‚úÖ",setTimeout(()=>t.innerText="üìã",2e3)},e.parentElement.style.position="relative",t.style.position="absolute",t.style.top="8px",t.style.right="8px",e.parentElement.appendChild(t)})</script><script>var enableTruncate=!0,filterDepth=!1;const MAX_DEPTH=9;window.addEventListener("DOMContentLoaded",()=>{const e=new IntersectionObserver(e=>{e.reverse().forEach(e=>{const n=e.target.getAttribute("id");if(e.intersectionRatio>0){var t=document.querySelectorAll(`nav li a[href="#${n}"]`);t!=null&&t.forEach(e=>{if(e!=null){var t=getDepth(e.parentElement);filterDepth&&t<=MAX_DEPTH&&(clearActiveStatesInTableOfContents(),e.parentElement.classList.add("active"))}else filterDepth||(clearActiveStatesInTableOfContents(),e.parentElement.classList.add("active"))})}})});document.querySelectorAll("h1[id],h2[id],h3[id],h4[id]").forEach(t=>{e.observe(t)})});function isVisible(e){if(!(e instanceof Element))return!1;const n=getComputedStyle(e);if(n.display==="none")return!1;if(n.visibility!=="visible")return!1;if(n.opacity<.1)return!1;if(e.offsetWidth+e.offsetHeight+e.getBoundingClientRect().height+e.getBoundingClientRect().width===0)return!1;const t={x:e.getBoundingClientRect().left+e.offsetWidth/2,y:e.getBoundingClientRect().top+e.offsetHeight/2};if(t.x<0)return!1;if(t.x>(document.documentElement.clientWidth||window.innerWidth))return!1;if(t.y<0)return!1;if(t.y>(document.documentElement.clientHeight||window.innerHeight))return!1;let s=document.elementFromPoint(t.x,t.y);do if(s===e)return!0;while(s=s.parentNode)return!1}function clearActiveStatesInTableOfContents(){document.querySelectorAll("nav li").forEach(e=>{e.classList.remove("active")})}function getDepth(e){for(var t=0;e!==null&&e.tagName.toLowerCase()!=="ul";)t++,e=e.parentElement;return t}function navItems(){var e=document.querySelectorAll("nav nav li a");return Array.from(e).filter(e=>e.href!=null&&e.hash.startsWith("#"))}function lasItemInNavBarVisible(){var e=navItems().slice(-1)[0];return isVisible(e)}document.addEventListener("DOMContentLoaded",function(){if(!enableTruncate)return;var e=navItems();console.log(e),lasItemInNavBarVisible()||(filterDepth=!0,e.forEach(function(e){var t=getDepth(e.parentElement);t>MAX_DEPTH&&e.parentElement.classList.add("depth-nested")}))})</script></body></html>